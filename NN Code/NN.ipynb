{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import sqlite3\n",
    "import pickle # menyimpan model\n",
    "from sklearn.model_selection import train_test_split # Untuk split data\n",
    "from sklearn.neural_network import MLPClassifier # Untuk Algoritma ML yang akan di pakai\n",
    "from sklearn.model_selection import GridSearchCV # untuk tuning hyperparameter\n",
    "from nltk.corpus import stopwords # untuk stopwords\n",
    "from sklearn.pipeline import Pipeline # untuk membangun pipeline ML\n",
    "from sklearn.compose import ColumnTransformer # bagian dari pipe line untuk handling kolom \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report# menghitung nilai f1\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung dimiliki pengusaha pabrik puluhan terke...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus k mmbri hujjah partai diwlh ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis jalan sumatra bandung nyaman ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia unboxing paket barang bagus men...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aduh mahasiswa sombong kasih kartu kuning bela...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet     Label\n",
       "0  warung dimiliki pengusaha pabrik puluhan terke...  positive\n",
       "1  mohon ulama lurus k mmbri hujjah partai diwlh ...   neutral\n",
       "2  lokasi strategis jalan sumatra bandung nyaman ...  positive\n",
       "3  betapa bahagia unboxing paket barang bagus men...  positive\n",
       "4  aduh mahasiswa sombong kasih kartu kuning bela...  negative"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(r'..\\database.db', check_same_thread=False)\n",
    "query = 'SELECT * FROM new_data'\n",
    "data = pd.read_sql_query (query, conn)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vektor = df.text_filter.tolist()\n",
    "data_vektor = data.Tweet.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "    \n",
    "# melakukan fitting dan transformasi pada dokumen\n",
    "count_vect.fit(data_vektor)\n",
    "\n",
    "# melihat hasil representasi bag of words\n",
    "X = count_vect.fit_transform(data_vektor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(count_vect, open(r\"..\\NN_Files\\feature_New.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MLPClassifier` is a neural network algorithm that can be used for classification tasks. It has several parameters that can be tuned to improve its performance. Here is an explanation of the parameters in your `parameter_grid`:\n",
    "\n",
    "- `hidden_layer_sizes`: This parameter specifies the number of neurons in each hidden layer of the neural network. It is a list of integers, where each integer represents the number of neurons in a hidden layer. For example, `[1, 10]` means that there are two hidden layers, one with 1 neuron and one with 10 neurons.\n",
    "\n",
    "- `activation`: This parameter specifies the activation function used in the neural network. The activation function is used to introduce non-linearity into the model. The possible values for this parameter are `'relu'`, `'tanh'`, and `'logistic'`.\n",
    "\n",
    "- `learning_rate_init`: This parameter specifies the initial learning rate used by the neural network. The learning rate determines how quickly the model learns from the data.\n",
    "\n",
    "- `alpha`: This parameter specifies the L2 penalty (regularization term) parameter. It is used to prevent overfitting of the model.\n",
    "\n",
    "- `early_stopping`: This parameter specifies whether to use early stopping to terminate training when validation score is not improving. If set to `True`, training will stop when validation score is not improving by at least `tol` for `n_iter_no_change` consecutive iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([ ('algoritma', MLPClassifier()) ])\n",
    "parameter_grid = {\n",
    "    'algoritma__hidden_layer_sizes': [{i} for i in [1, 10]],\n",
    "    'algoritma__activation': ['relu','tanh','logistic'],\n",
    "    'algoritma__learning_rate_init' : [0.01],\n",
    "    'algoritma__alpha': [0.1,0.01,1],\n",
    "    'algoritma__early_stopping': [True]\n",
    "} \n",
    "\n",
    "model_NN = GridSearchCV(model, parameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.2 s\n",
      "Wall time: 2min 18s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;algoritma&#x27;, MLPClassifier())]),\n",
       "             param_grid={&#x27;algoritma__activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;, &#x27;logistic&#x27;],\n",
       "                         &#x27;algoritma__alpha&#x27;: [0.1, 0.01, 1],\n",
       "                         &#x27;algoritma__early_stopping&#x27;: [True],\n",
       "                         &#x27;algoritma__hidden_layer_sizes&#x27;: [{1}, {10}],\n",
       "                         &#x27;algoritma__learning_rate_init&#x27;: [0.01]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;algoritma&#x27;, MLPClassifier())]),\n",
       "             param_grid={&#x27;algoritma__activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;, &#x27;logistic&#x27;],\n",
       "                         &#x27;algoritma__alpha&#x27;: [0.1, 0.01, 1],\n",
       "                         &#x27;algoritma__early_stopping&#x27;: [True],\n",
       "                         &#x27;algoritma__hidden_layer_sizes&#x27;: [{1}, {10}],\n",
       "                         &#x27;algoritma__learning_rate_init&#x27;: [0.01]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;algoritma&#x27;, MLPClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('algoritma', MLPClassifier())]),\n",
       "             param_grid={'algoritma__activation': ['relu', 'tanh', 'logistic'],\n",
       "                         'algoritma__alpha': [0.1, 0.01, 1],\n",
       "                         'algoritma__early_stopping': [True],\n",
       "                         'algoritma__hidden_layer_sizes': [{1}, {10}],\n",
       "                         'algoritma__learning_rate_init': [0.01]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_NN.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algoritma__activation': 'tanh',\n",
       " 'algoritma__alpha': 0.1,\n",
       " 'algoritma__early_stopping': True,\n",
       " 'algoritma__hidden_layer_sizes': {10},\n",
       " 'algoritma__learning_rate_init': 0.01}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NN.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_NN, open(r\"..\\NN_Files\\model_NN.pickle\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA TRAIN - DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_NN.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90      3412\n",
      "     neutral       0.94      0.87      0.90      1138\n",
      "    positive       0.95      0.95      0.95      6383\n",
      "\n",
      "    accuracy                           0.93     10933\n",
      "   macro avg       0.93      0.91      0.92     10933\n",
      "weighted avg       0.93      0.93      0.93     10933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA TRAIN - DATA TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model_NN.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.95      0.94      2725\n",
      "     neutral       0.97      0.94      0.96       907\n",
      "    positive       0.97      0.97      0.97      5114\n",
      "\n",
      "    accuracy                           0.96      8746\n",
      "   macro avg       0.96      0.95      0.95      8746\n",
      "weighted avg       0.96      0.96      0.96      8746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA TRAIN - DATA TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model_NN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.84      0.82       687\n",
      "     neutral       0.84      0.73      0.78       231\n",
      "    positive       0.91      0.91      0.91      1269\n",
      "\n",
      "    accuracy                           0.87      2187\n",
      "   macro avg       0.85      0.83      0.84      2187\n",
      "weighted avg       0.87      0.87      0.87      2187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CROSS VALIDATION - WITHOUT PIPELINE PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ke- 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.72      0.71       690\n",
      "     neutral       0.69      0.52      0.59       220\n",
      "    positive       0.84      0.86      0.85      1277\n",
      "\n",
      "    accuracy                           0.78      2187\n",
      "   macro avg       0.74      0.70      0.72      2187\n",
      "weighted avg       0.78      0.78      0.78      2187\n",
      "\n",
      "======================================================================\n",
      "Training ke- 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.71      0.71       667\n",
      "     neutral       0.70      0.58      0.64       219\n",
      "    positive       0.85      0.87      0.86      1301\n",
      "\n",
      "    accuracy                           0.79      2187\n",
      "   macro avg       0.75      0.72      0.74      2187\n",
      "weighted avg       0.79      0.79      0.79      2187\n",
      "\n",
      "======================================================================\n",
      "Training ke- 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.70      0.71       695\n",
      "     neutral       0.72      0.60      0.65       213\n",
      "    positive       0.85      0.88      0.86      1279\n",
      "\n",
      "    accuracy                           0.80      2187\n",
      "   macro avg       0.76      0.73      0.74      2187\n",
      "weighted avg       0.79      0.80      0.80      2187\n",
      "\n",
      "======================================================================\n",
      "Training ke- 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.72      0.71       705\n",
      "     neutral       0.73      0.61      0.67       234\n",
      "    positive       0.84      0.86      0.85      1247\n",
      "\n",
      "    accuracy                           0.79      2186\n",
      "   macro avg       0.76      0.73      0.74      2186\n",
      "weighted avg       0.79      0.79      0.79      2186\n",
      "\n",
      "======================================================================\n",
      "Training ke- 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.66      0.65       655\n",
      "     neutral       0.66      0.52      0.58       252\n",
      "    positive       0.83      0.86      0.84      1279\n",
      "\n",
      "    accuracy                           0.76      2186\n",
      "   macro avg       0.71      0.68      0.69      2186\n",
      "weighted avg       0.76      0.76      0.76      2186\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "Rata-rata Accuracy:  0.784320556762471\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42,shuffle=True)\n",
    "accuracies = []\n",
    "\n",
    "for iteration, data in enumerate(kf.split(X), start=1):\n",
    "\n",
    "  data_train = X[data[0]]\n",
    "  target_train = y[data[0]]\n",
    "\n",
    "  data_test = X[data[1]]\n",
    "  target_test = y[data[1]]\n",
    "\n",
    "  # Create model architecture\n",
    "  model = MLPClassifier()\n",
    "  model.fit(data_train, target_train)\n",
    "\n",
    "  predictions = model.predict(data_test)\n",
    "  y_pred = predictions\n",
    "\n",
    "  # for the current fold only\n",
    "  accuracy = accuracy_score(target_test,predictions)\n",
    "\n",
    "  print(\"Training ke-\", iteration)\n",
    "  print(classification_report(target_test,predictions))\n",
    "  print(\"======================================================================\")\n",
    "\n",
    "  accuracies.append(accuracy)\n",
    "\n",
    "# this is the average accuracy over all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Rata-rata Accuracy: \", average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CROSS VALIDATION - WITH PIPELINE PARAMETER\n",
    "\n",
    "This code will split your dataset into n_splits folds, train an MLPClassifier model on each fold, and test the model on the remaining folds. The GridSearchCV object will perform a search over the parameter grid to find the best hyperparameters for the model. The best hyperparameters will be used to create a new MLPClassifier object, which will be used to obtain the predictions using cross_val_predict. Finally, the confusion matrix, f1 score, precision score, recall score, and accuracy score will be computed and printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ke- 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.79      0.80       690\n",
      "     neutral       0.78      0.74      0.76       220\n",
      "    positive       0.90      0.92      0.91      1277\n",
      "\n",
      "    accuracy                           0.86      2187\n",
      "   macro avg       0.83      0.82      0.82      2187\n",
      "weighted avg       0.86      0.86      0.86      2187\n",
      "\n",
      "======================================================================\n",
      "Confusion matrix:\n",
      " [[2153  105  464]\n",
      " [ 274  534  110]\n",
      " [ 394   55 4657]]\n",
      "Best parameters:  {'algoritma__activation': 'relu', 'algoritma__alpha': 0.1, 'algoritma__early_stopping': True, 'algoritma__hidden_layer_sizes': {10}, 'algoritma__learning_rate_init': 0.01}\n",
      "Training ke- 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.83      0.79       667\n",
      "     neutral       0.82      0.61      0.70       219\n",
      "    positive       0.92      0.91      0.91      1301\n",
      "\n",
      "    accuracy                           0.85      2187\n",
      "   macro avg       0.83      0.78      0.80      2187\n",
      "weighted avg       0.86      0.85      0.85      2187\n",
      "\n",
      "======================================================================\n",
      "Confusion matrix:\n",
      " [[2183  106  456]\n",
      " [ 274  546   99]\n",
      " [ 397   49 4636]]\n",
      "Best parameters:  {'algoritma__activation': 'relu', 'algoritma__alpha': 0.1, 'algoritma__early_stopping': True, 'algoritma__hidden_layer_sizes': {10}, 'algoritma__learning_rate_init': 0.01}\n",
      "Training ke- 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.78      0.79       695\n",
      "     neutral       0.75      0.72      0.74       213\n",
      "    positive       0.90      0.91      0.90      1279\n",
      "\n",
      "    accuracy                           0.85      2187\n",
      "   macro avg       0.82      0.80      0.81      2187\n",
      "weighted avg       0.85      0.85      0.85      2187\n",
      "\n",
      "======================================================================\n",
      "Confusion matrix:\n",
      " [[2172  106  439]\n",
      " [ 251  554  120]\n",
      " [ 415   56 4633]]\n",
      "Best parameters:  {'algoritma__activation': 'relu', 'algoritma__alpha': 0.01, 'algoritma__early_stopping': True, 'algoritma__hidden_layer_sizes': {10}, 'algoritma__learning_rate_init': 0.01}\n",
      "Training ke- 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.79      0.78       705\n",
      "     neutral       0.79      0.66      0.72       234\n",
      "    positive       0.89      0.90      0.89      1247\n",
      "\n",
      "    accuracy                           0.84      2186\n",
      "   macro avg       0.82      0.78      0.80      2186\n",
      "weighted avg       0.84      0.84      0.84      2186\n",
      "\n",
      "======================================================================\n",
      "Confusion matrix:\n",
      " [[2178  101  428]\n",
      " [ 316  476  112]\n",
      " [ 437   47 4652]]\n",
      "Best parameters:  {'algoritma__activation': 'relu', 'algoritma__alpha': 0.1, 'algoritma__early_stopping': True, 'algoritma__hidden_layer_sizes': {10}, 'algoritma__learning_rate_init': 0.01}\n",
      "Training ke- 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.79      0.78       655\n",
      "     neutral       0.73      0.57      0.64       252\n",
      "    positive       0.90      0.92      0.91      1279\n",
      "\n",
      "    accuracy                           0.84      2186\n",
      "   macro avg       0.80      0.76      0.78      2186\n",
      "weighted avg       0.84      0.84      0.84      2186\n",
      "\n",
      "======================================================================\n",
      "Confusion matrix:\n",
      " [[2195  102  460]\n",
      " [ 277  503  106]\n",
      " [ 409   53 4642]]\n",
      "Best parameters:  {'algoritma__activation': 'tanh', 'algoritma__alpha': 0.01, 'algoritma__early_stopping': True, 'algoritma__hidden_layer_sizes': {10}, 'algoritma__learning_rate_init': 0.01}\n",
      "\n",
      "\n",
      "\n",
      "Rata-rata Accuracy:  0.8494450071138988\n",
      "Best parameters:  {'algoritma__activation': 'tanh', 'algoritma__alpha': 0.01, 'algoritma__early_stopping': True, 'algoritma__hidden_layer_sizes': {10}, 'algoritma__learning_rate_init': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42,shuffle=True)\n",
    "accuracies = []\n",
    "\n",
    "for iteration, data in enumerate(kf.split(X), start=1):\n",
    "\n",
    "  data_train = X[data[0]]\n",
    "  target_train = y[data[0]]\n",
    "\n",
    "  data_test = X[data[1]]\n",
    "  target_test = y[data[1]]\n",
    "\n",
    "  # Create an MLPClassifier object\n",
    "  clf = MLPClassifier()\n",
    "\n",
    "  # Create a pipeline object\n",
    "  pipeline = Pipeline(steps=[('algoritma', clf)])\n",
    "\n",
    "  # Define the parameter grid\n",
    "  parameter_grid = {\n",
    "      'algoritma__hidden_layer_sizes': [{i} for i in [1, 10]],\n",
    "      'algoritma__activation': ['relu','tanh','logistic'],\n",
    "      'algoritma__learning_rate_init' : [0.01],\n",
    "      'algoritma__alpha': [0.1,0.01,1],\n",
    "      'algoritma__early_stopping': [True]\n",
    "  }\n",
    "\n",
    "  # Create a GridSearchCV object\n",
    "  grid_search = GridSearchCV(pipeline, parameter_grid, cv=kf)\n",
    "\n",
    "  # Fit the GridSearchCV object to the data\n",
    "  grid_search.fit(data_train, target_train)\n",
    "\n",
    "  predictions = grid_search.predict(data_test)\n",
    "\n",
    "  # Use cross_val_predict to obtain the predictions\n",
    "  y_prediction = cross_val_predict(grid_search.best_estimator_, data_train, target_train, cv=kf)\n",
    "\n",
    "  # for the current fold only\n",
    "\n",
    "  accuracy = accuracy_score(target_test,predictions)\n",
    "\n",
    "  print(\"Training ke-\", iteration)\n",
    "  print(classification_report(target_test,predictions))\n",
    "  print(\"======================================================================\")\n",
    "\n",
    "  accuracies.append(accuracy)\n",
    "\n",
    "  # Compute the confusion matrix\n",
    "  conf_mat = confusion_matrix(target_train, y_prediction)\n",
    "\n",
    "  # Print the confusion matrix\n",
    "  print(\"Confusion matrix:\\n\", conf_mat)\n",
    "\n",
    "  print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# this is the average accuracy over all folds\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Rata-rata Accuracy: \", average_accuracy)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:   (0, 5732)\t1\n",
      "  (0, 7036)\t1\n",
      "  (0, 7111)\t1\n",
      "  (0, 8096)\t1\n",
      "Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"Dia memakan kue dengan lahap dan beringas jelek\"\"\"\n",
    "def cleansing(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))', ' ', text)\n",
    "    text = re.sub(r'pic.twitter.com.[\\w]+', ' ', text)\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = text.replace('user', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub('url',' ', text)\n",
    "    return text\n",
    "\n",
    "sentiment = ['negative', 'neutral', 'positive']\n",
    "\n",
    "text = [cleansing(input_text)]\n",
    "text = count_vect.transform(text)\n",
    "\n",
    "count_vect = pickle.load(open(r\"..\\NN_Files\\feature_New.pickle\", \"rb\"))\n",
    "model_NN = pickle.load(open(r\"..\\NN_Files\\model_NN.pickle\", \"rb\"))\n",
    "\n",
    "prediction = model_NN.predict(text)\n",
    "polarity = np.argmax(prediction[0])\n",
    "hasil = sentiment[polarity]\n",
    "\n",
    "print(\"Text: %s\" % text[0])\n",
    "print(\"Sentiment: %s\" % sentiment[polarity])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
